## Theorem: \[*Lippmann, Richard*\]
If we reach the global minimum using $0/1$ targets and the right **MLP** architecture, we are guaranteed that the **MLP** obtained this way is the optimal **Bayesian Classifier**, as long as the class-posteriors are continuous.

*In practice, using backpropagation on real world data we will never find the global minimum*.


---
# Original Files
![[Pasted image 20220819145510.png]]
