## Universality of an MLP
*A non-linear MLP is very flexible*:

According tho the theorem of *Universality of MLP*, an MLP with a hidden layer of sigmoid function an and a linear output is a **universal machine**.

Given an unspecified number of neurons, and an unspecified method to learn the correct values of the weights, an MLP with just 1 hidden layer and sigmoid functions can generalize any function $\phi : \mathbb{R}^d \to \mathbb{R}^m$.

---
# Original Files
![[Pasted image 20220818111139.png]]
![[Pasted image 20220818111213.png]]
